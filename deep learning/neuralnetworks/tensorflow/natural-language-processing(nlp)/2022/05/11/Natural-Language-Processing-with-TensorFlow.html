<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Natural Language Processing(NLP) with TensorFlow - Live Blog post | Sandesh’s Machine Learning Journal</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Natural Language Processing(NLP) with TensorFlow - Live Blog post" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Notebook demonstrates Natural Language Processing using TensorFlow" />
<meta property="og:description" content="Notebook demonstrates Natural Language Processing using TensorFlow" />
<link rel="canonical" href="https://sandeshkatakam.github.io/My-Machine_learning-Blog/deep%20learning/neuralnetworks/tensorflow/natural-language-processing(nlp)/2022/05/11/Natural-Language-Processing-with-TensorFlow.html" />
<meta property="og:url" content="https://sandeshkatakam.github.io/My-Machine_learning-Blog/deep%20learning/neuralnetworks/tensorflow/natural-language-processing(nlp)/2022/05/11/Natural-Language-Processing-with-TensorFlow.html" />
<meta property="og:site_name" content="Sandesh’s Machine Learning Journal" />
<meta property="og:image" content="https://sandeshkatakam.github.io/My-Machine_learning-Blog/images/nlp.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-05-11T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://sandeshkatakam.github.io/My-Machine_learning-Blog/images/nlp.png" />
<meta property="twitter:title" content="Natural Language Processing(NLP) with TensorFlow - Live Blog post" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-05-11T00:00:00-05:00","datePublished":"2022-05-11T00:00:00-05:00","description":"Notebook demonstrates Natural Language Processing using TensorFlow","headline":"Natural Language Processing(NLP) with TensorFlow - Live Blog post","image":"https://sandeshkatakam.github.io/My-Machine_learning-Blog/images/nlp.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://sandeshkatakam.github.io/My-Machine_learning-Blog/deep%20learning/neuralnetworks/tensorflow/natural-language-processing(nlp)/2022/05/11/Natural-Language-Processing-with-TensorFlow.html"},"url":"https://sandeshkatakam.github.io/My-Machine_learning-Blog/deep%20learning/neuralnetworks/tensorflow/natural-language-processing(nlp)/2022/05/11/Natural-Language-Processing-with-TensorFlow.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/My-Machine_learning-Blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://sandeshkatakam.github.io/My-Machine_learning-Blog/feed.xml" title="Sandesh's Machine Learning Journal" />
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.2/jquery.min.js"></script>
<script>
 $(document).ready(function () {
     $(window).scroll(function () {
         if ($(this).scrollTop() > 100) {
             $('.scrollup').fadeIn();
         } else {
             $('.scrollup').fadeOut();
         }
     });
     $('.scrollup').click(function () {
         $("html, body").animate({
             scrollTop: 0
         }, 600);
         return false;
     });
 });
</script>

<style>
      .img-container {
        text-align: center;
        display: block;
      }
    </style>
 
<style>
      marquee{
      font-size: 15px;
      font-weight: 500;
      color: #fafafa;
      font-family: 'Playfair Display', serif;
      }
</style><link rel="shortcut icon" type="image/x-icon" href="/My-Machine_learning-Blog/images/favicon.ico">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<title>Sandesh's Machine Learning Journal</title>
<meta name="description" content="A Blog related to Machine Learning and Deep learning">
<meta property="og:title" content="Sandesh's Machine learning Journal" />
<meta property="og:url" content="https://sandeshkatakam.github.io/My-Machine_learning-Blog/" />
<meta property="og:description" content="A Blog related to Machine learning and Deep Learning">
<meta property="og:image" content="/images/mstile-150x150.png">
<meta property="og:type" content="article" />

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" /> 
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" /><script src="https://hypothes.is/embed.js" async></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script> 
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/My-Machine_learning-Blog/">Sandesh&#39;s Machine Learning Journal</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/My-Machine_learning-Blog/about/">About Me</a><a class="page-link" href="/My-Machine_learning-Blog/search/">Search</a><a class="page-link" href="/My-Machine_learning-Blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting"> 


  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Natural Language Processing(NLP) with TensorFlow - Live Blog post</h1><p class="page-description">Notebook demonstrates Natural Language Processing using TensorFlow</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-05-11T00:00:00-05:00" itemprop="datePublished">
        May 11, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      16 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/My-Machine_learning-Blog/categories/#Deep Learning">Deep Learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/My-Machine_learning-Blog/categories/#NeuralNetworks">NeuralNetworks</a>
        &nbsp;
      
        <a class="category-tags-link" href="/My-Machine_learning-Blog/categories/#TensorFlow">TensorFlow</a>
        &nbsp;
      
        <a class="category-tags-link" href="/My-Machine_learning-Blog/categories/#Natural-Language-Processing(NLP)">Natural-Language-Processing(NLP)</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/sandeshkatakam/My-Machine_learning-Blog/tree/master/_notebooks/2022-05-11-Natural-Language-Processing-with-TensorFlow.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/My-Machine_learning-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/sandeshkatakam/My-Machine_learning-Blog/master?filepath=_notebooks%2F2022-05-11-Natural-Language-Processing-with-TensorFlow.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/My-Machine_learning-Blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/sandeshkatakam/My-Machine_learning-Blog/blob/master/_notebooks/2022-05-11-Natural-Language-Processing-with-TensorFlow.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/My-Machine_learning-Blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fsandeshkatakam%2FMy-Machine_learning-Blog%2Fblob%2Fmaster%2F_notebooks%2F2022-05-11-Natural-Language-Processing-with-TensorFlow.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/My-Machine_learning-Blog/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>
  
  

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introduction-to-Natural-Language-Processing-(NLP)-Fundamentals-in-TensorFlow">Introduction to Natural Language Processing (NLP) Fundamentals in TensorFlow </a>
<ul>
<li class="toc-entry toc-h3"><a href="#What-is-a-Recurrent-Neural-Network?">What is a Recurrent Neural Network? </a></li>
<li class="toc-entry toc-h3"><a href="#Architecture-of-an-RNN:">Architecture of an RNN: </a></li>
<li class="toc-entry toc-h3"><a href="#Get-Helper-Functions">Get Helper Functions </a></li>
<li class="toc-entry toc-h3"><a href="#Get-Text-Dataset">Get Text Dataset </a></li>
<li class="toc-entry toc-h3"><a href="#Visualizing-a-text-dataset">Visualizing a text dataset </a></li>
<li class="toc-entry toc-h3"><a href="#Split-data-into-training-and-validation-sets">Split data into training and validation sets </a></li>
<li class="toc-entry toc-h3"><a href="#Converting-text-into-numbers">Converting text into numbers </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Text-Vectorization(Tokenization)">Text Vectorization(Tokenization) </a></li>
<li class="toc-entry toc-h4"><a href="#Creating-and-Embedding-using-an-Emedding-Layer">Creating and Embedding using an Emedding Layer </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Modelling-a-text-dataset">Modelling a text dataset </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Model-0:-Naive-Bayes-with-TF-IDF-encoder">Model 0: Naive Bayes with TF-IDF encoder </a></li>
<li class="toc-entry toc-h4"><a href="#Creating-an-evaluation-function-for-our-model-experiments">Creating an evaluation function for our model experiments </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Model-1:-A-Simple-Dense-Model">Model 1: A Simple Dense Model </a></li>
<li class="toc-entry toc-h3"><a href="#Visualizing-learned-Embeddings:">Visualizing learned Embeddings: </a></li>
</ul>
</li>
</ul><script src="https://sandeshkatakam.github.io/assets/button.js"></script>
<a name="top"></a>
<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-05-11-Natural-Language-Processing-with-TensorFlow.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction-to-Natural-Language-Processing-(NLP)-Fundamentals-in-TensorFlow">
<a class="anchor" href="#Introduction-to-Natural-Language-Processing-(NLP)-Fundamentals-in-TensorFlow" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction to Natural Language Processing (NLP) Fundamentals in TensorFlow<a class="anchor-link" href="#Introduction-to-Natural-Language-Processing-(NLP)-Fundamentals-in-TensorFlow"> </a>
</h2>
<p>NLP has the goal of deriving information out of natural language(could be a sequences test or speech).</p>
<p>Another common term for NLP problems is Sequence Models/ Sequence to Sequence problems</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>some common applications of NLP:</p>
<ul>
<li>Classification of articles into labels</li>
<li>Text Generation</li>
<li>Machine Translation</li>
<li>Voice Assistants.  </li>
</ul>
<p>All of there are also referred to as <strong>Sequence Problems</strong></p>
<p>Different Types of Sequence Problems:<br>
<img src="https://camo.githubusercontent.com/61cd232998541a3dd8e3b72bd25035940f373c1a4bd745fbe68e6424345adcb2/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f62347375732e6a7067" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This Notebook covers:</p>
<ul>
<li>Downloading and preparing a text dataset</li>
<li>How to prepare text data for modelling(tokenization and embedding)</li>
<li>Setting up multiple modelling experiments with recurrent neural networks(RNNs)</li>
<li>Building a text feature extraction model using TensorFlow Hub</li>
<li>Finding the most wrong prediction examples  </li>
<li>Using a model we've built to make predictions on text from the wild.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="What-is-a-Recurrent-Neural-Network?">
<a class="anchor" href="#What-is-a-Recurrent-Neural-Network?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What is a <strong>Recurrent Neural Network</strong>?<a class="anchor-link" href="#What-is-a-Recurrent-Neural-Network?"> </a>
</h3>
<p>Answer goes here...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Architecture-of-an-RNN:">
<a class="anchor" href="#Architecture-of-an-RNN:" aria-hidden="true"><span class="octicon octicon-link"></span></a>Architecture of an RNN:<a class="anchor-link" href="#Architecture-of-an-RNN:"> </a>
</h3>
<table>
<thead>
<tr>
<th>Hyperparamter/Layer type</th>
<th>What does it do?</th>
<th>Typical values</th>
</tr>
</thead>
<tbody>
<tr>
<td>Input text(s)</td>
<td>Target texts/sequences you'd like to discover patterns in</td>
<td>Whatever you can represent as a text or a sequence</td>
</tr>
<tr>
<td>Input layer</td>
<td>Takes in a target sequence</td>
<td><code>input_shape = [batch_size, embeddding_size] or [batch_size, sequence_shape]</code></td>
</tr>
<tr>
<td>Text Vectorization layer</td>
<td>Maps input sequences to numbers</td>
<td>Multiple, can create with <code>tf.keras.layers.experimental.preprocessing.TextVectorization</code>
</td>
</tr>
<tr>
<td>Embedding</td>
<td>Turns mapping of text vectors to embedding matrix(representation of how words realate)</td>
<td>Multiple, can create with <code>tf.keras.layers.Embedding</code>
</td>
</tr>
<tr>
<td>RNN Cell(s)</td>
<td>Finds patterns in sequences</td>
<td>Simple RNN, LSTM, GRU</td>
</tr>
<tr>
<td>Hidden activation</td>
<td>Adds non-linearity to learned features(non-straight lines)</td>
<td>Usually Tanh(hyperbolic tangent)(<code>tf.keras.activations.tanh</code>)</td>
</tr>
<tr>
<td>Pooling layer</td>
<td>Reduces the dimensionality of learned sequence features (usually Conv1D models)</td>
<td>Average(<code>tf.keras.layers.GlobalAveragePooling1D</code> or Max(<code>tf.keras.layers.GlobalMaxPool1D</code>)</td>
</tr>
<tr>
<td>Fully connected layer</td>
<td>Further refines learned features from recurrent layers</td>
<td>tf.keras.layers.Dense</td>
</tr>
<tr>
<td>Output layer</td>
<td>Takes learned features and outputs them in shape of target labels</td>
<td>
<code>output_shape = [number_of_classes]</code>(e.g. 2 for Disaster/Not Disaster example)</td>
</tr>
<tr>
<td>Output activation</td>
<td>Adds non-linearities to output layer</td>
<td>
<code>tf.keras.activations.sigmoid</code>(binary classification) or <code>tf.keras.activations.softmax</code>
</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Example TensorFlow code for RNN Model:</p>

<pre><code>#1. Create LSTM model
from tensorflow.keras import layers
inputs = layers.Input(shape = (1,), dtype = "string")
x = text_vectorizer(inputs) # turn inputs sequence to numbers
x = embedding(x) # Create embedding matrix 
x = layers.LSTM(64, activation = "tanh")(x)
outputs = layers.Dense(1, activation = "sigmoid")(x)
model = tf.keras.Model(inputs,outputs, name = "LSTM_model")

# 2. Compile the Model
model.compile(loss = tf.keras.losses.BinaryCrossentropy(),
              optimzer = tf.keras.optimizers.Adam(),
              metrics = ["accuracy"])

# 3. Fit the model
history = model.fit(train_sentences, train_labels, epochs = 5)</code></pre>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span> <span class="o">-</span><span class="n">L</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>GPU 0: Tesla K80 (UUID: GPU-b8f44027-0c2b-aba8-bdea-b2db6b2c6f28)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Get-Helper-Functions">
<a class="anchor" href="#Get-Helper-Functions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Get Helper Functions<a class="anchor-link" href="#Get-Helper-Functions"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="o">.</span><span class="n">githubusercontent</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">mrdbourke</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">extras</span><span class="o">/</span><span class="n">helper_functions</span><span class="o">.</span><span class="n">py</span>

<span class="c1"># Import a series of helper functions for the notebook</span>
<span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">unzip_data</span><span class="p">,</span> <span class="n">create_tensorboard_callback</span><span class="p">,</span><span class="n">plot_loss_curves</span><span class="p">,</span><span class="n">compare_historys</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2022-03-11 07:41:53--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 10246 (10K) [text/plain]
Saving to: ‘helper_functions.py.1’

helper_functions.py 100%[===================&gt;]  10.01K  --.-KB/s    in 0s      

2022-03-11 07:41:53 (74.3 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Get-Text-Dataset">
<a class="anchor" href="#Get-Text-Dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Get Text Dataset<a class="anchor-link" href="#Get-Text-Dataset"> </a>
</h3>
<p>The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster)</p>
<p>Source : <a href="https://www.kaggle.com/c/nlp-getting-started">Natural Language Processing with Disaster Tweets</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">storage</span><span class="o">.</span><span class="n">googleapis</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">ztm_tf_course</span><span class="o">/</span><span class="n">nlp_getting_started</span><span class="o">.</span><span class="n">zip</span>

<span class="c1"># Unzip the dataset</span>
<span class="n">unzip_data</span><span class="p">(</span><span class="s2">"nlp_getting_started.zip"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2022-03-11 07:41:53--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip
Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 108.177.15.128, 173.194.76.128, ...
Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 607343 (593K) [application/zip]
Saving to: ‘nlp_getting_started.zip.1’

nlp_getting_started 100%[===================&gt;] 593.11K  --.-KB/s    in 0.007s  

2022-03-11 07:41:53 (85.5 MB/s) - ‘nlp_getting_started.zip.1’ saved [607343/607343]

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Visualizing-a-text-dataset">
<a class="anchor" href="#Visualizing-a-text-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visualizing a text dataset<a class="anchor-link" href="#Visualizing-a-text-dataset"> </a>
</h3>
<p>To visualize our text samples, we have to read them in, one way to do this is to be use python.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"train.csv"</span><span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"test.csv"</span><span class="p">)</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-ccb6fb0d-83de-45fd-a88b-d4598dff70fd">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-ccb6fb0d-83de-45fd-a88b-d4598dff70fd')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  &lt;/svg&gt;
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-ccb6fb0d-83de-45fd-a88b-d4598dff70fd button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-ccb6fb0d-83de-45fd-a88b-d4598dff70fd');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train_df_shuffled</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">train_df_shuffled</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-22179ab9-9517-4887-a4bc-c4844d59900d">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2644</th>
      <td>3796</td>
      <td>destruction</td>
      <td>NaN</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2227</th>
      <td>3185</td>
      <td>deluge</td>
      <td>NaN</td>
      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5448</th>
      <td>7769</td>
      <td>police</td>
      <td>UK</td>
      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>132</th>
      <td>191</td>
      <td>aftershock</td>
      <td>NaN</td>
      <td>Aftershock back to school kick off was great. ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6845</th>
      <td>9810</td>
      <td>trauma</td>
      <td>Montgomery County, MD</td>
      <td>in response to trauma Children of Addicts deve...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-22179ab9-9517-4887-a4bc-c4844d59900d')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  &lt;/svg&gt;
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-22179ab9-9517-4887-a4bc-c4844d59900d button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-22179ab9-9517-4887-a4bc-c4844d59900d');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">test_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-2aec6a35-328f-4ca1-aa9c-7ddbe51d3f42">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just happened a terrible car crash</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Heard about #earthquake is different cities, s...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>there is a forest fire at spot pond, geese are...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Apocalypse lighting. #Spokane #wildfires</td>
    </tr>
    <tr>
      <th>4</th>
      <td>11</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-2aec6a35-328f-4ca1-aa9c-7ddbe51d3f42')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  &lt;/svg&gt;
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-2aec6a35-328f-4ca1-aa9c-7ddbe51d3f42 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-2aec6a35-328f-4ca1-aa9c-7ddbe51d3f42');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0    4342
1    3271
Name: target, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(7613, 3263)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="n">random_index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># Create random indexes </span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">train_df_shuffled</span><span class="p">[[</span><span class="s2">"text"</span><span class="p">,</span> <span class="s2">"target"</span><span class="p">]][</span><span class="n">random_index</span><span class="p">:</span> <span class="n">random_index</span><span class="o">+</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">row</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Target:</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="s2">"(real disaster)"</span> <span class="k">if</span> <span class="n">target</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">"(not real disaster)"</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Text:</span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"---</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Target:1 (real disaster)
Text:
 News Update Huge cliff landslide on road in China - Watch the moment a cliff collapses as huge chunks of rock fall... http://t.co/gaBd0cjmAG 

---

Target:1 (real disaster)
Text:
 #Politics DemocracyÛªs hatred for hate: Û_ Dawabsha threaten to erode Israeli democracy. Homegrown terrorism ha...  http://t.co/q8n5Tn8WME 

---

Target:0 (not real disaster)
Text:
 Be Trynna smoke TJ out but he a hoe 

---

Target:1 (real disaster)
Text:
 California LawÛÓNegligence and Fireworks Explosion Incidents http://t.co/d5w2zynP7b 

---

Target:1 (real disaster)
Text:
 USGS EQ: M 1.2 - 23km S of Twentynine Palms California: Time2015-08-05 23:54:09 UTC2015-08-05 16:... http://t.co/T97JmbzOBO #EarthQuake 

---

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Split-data-into-training-and-validation-sets">
<a class="anchor" href="#Split-data-into-training-and-validation-sets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Split data into training and validation sets<a class="anchor-link" href="#Split-data-into-training-and-validation-sets"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train_sentences</span><span class="p">,</span> <span class="n">val_sentences</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_df_shuffled</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                                                                            <span class="n">train_df_shuffled</span><span class="p">[</span><span class="s2">"target"</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                                                                            <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span><span class="c1"># use 10% of training data for validation </span>
                                                                            <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_sentences</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_labels</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(6851, 762, 6851, 762)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train_sentences</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">train_labels</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(array(['@mogacola @zamtriossu i screamed after hitting tweet',
        'Imagine getting flattened by Kurt Zouma',
        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',
        "@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet",
        'Somehow find you and I collide http://t.co/Ee8RpOahPk',
        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',
        'destroy the free fandom honestly',
        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',
        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',
        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],
       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Converting-text-into-numbers">
<a class="anchor" href="#Converting-text-into-numbers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Converting text into numbers<a class="anchor-link" href="#Converting-text-into-numbers"> </a>
</h3>
<p>When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.</p>
<p>There are a few ways to do this, namely:</p>
<ul>
<li>
<p><strong>Tokenization:</strong> Straight mapping from token to number(can be modelled but quickly gets too big)</p>
</li>
<li>
<p><strong>Embedding:</strong>  richer representation of relationships between tokens (can limit size + can be learned)</p>
</li>
</ul>
<p><strong>Tokenization vs Embedding</strong></p>
<p>E.g. I am a Human</p>

<pre><code>I = 0  
am = 1  
a = 2
Human = 3</code></pre>
<p>or using <strong>one-hot enconding</strong></p>

<pre><code>[[1,0,0,0],
 [0,1,0,0]
 [0,0,1,0]
 [0,0,0,1]]</code></pre>
<p>or by creating an <strong>Embedding</strong></p>

<pre><code>[[0.492, 0.005, 0.019],
 [0.060, 0.233, 0.899],
 [0.741, 0.983, 0.567]]</code></pre>
<p>There are a few ways to do this, namely:</p>
<ul>
<li>
<p><strong>Tokenization:</strong> Straight mapping from token to number(can be modelled but quickly gets too big)</p>
</li>
<li>
<p><strong>Embedding:</strong>  richer representation of relationships between tokens (can limit size + can be learned)</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Text-Vectorization(Tokenization)">
<a class="anchor" href="#Text-Vectorization(Tokenization)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Text Vectorization(Tokenization)<a class="anchor-link" href="#Text-Vectorization(Tokenization)"> </a>
</h4>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train_sentences</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array(['@mogacola @zamtriossu i screamed after hitting tweet',
       'Imagine getting flattened by Kurt Zouma',
       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',
       "@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet",
       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],
      dtype=object)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers.experimental.preprocessing</span> <span class="kn">import</span> <span class="n">TextVectorization</span>

<span class="c1"># Use the default TextVectorization parameters(just to demonstrate the default values of this instance)</span>
<span class="n">text_vectorizer</span> <span class="o">=</span> <span class="n">TextVectorization</span><span class="p">(</span><span class="n">max_tokens</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># how many words in the vocabulary(automatically add &lt;OOV?)</span>
                                    <span class="n">standardize</span> <span class="o">=</span> <span class="s2">"lower_and_strip_punctuation"</span><span class="p">,</span>
                                    <span class="n">split</span> <span class="o">=</span> <span class="s2">"whitespace"</span><span class="p">,</span> <span class="c1"># or SPLIT_WHITESPACE also works</span>
                                    <span class="n">ngrams</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Create groups of n-words</span>
                                    <span class="n">output_mode</span> <span class="o">=</span><span class="s2">"int"</span><span class="p">,</span> <span class="c1"># How to map token to numbers</span>
                                    <span class="n">output_sequence_length</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="c1">#  how long do you want the sequences to be</span>
                                    <span class="c1">#pad_to_max_tokens = True) not valid if using max_tokens=None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>7</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">round</span><span class="p">(</span><span class="nb">sum</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train_sentences</span><span class="p">])</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>15</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">max_vocab_length</span>  <span class="o">=</span> <span class="mi">10000</span> <span class="c1"># max number of words to have in our vocabulary</span>
<span class="n">max_length</span> <span class="o">=</span> <span class="mi">15</span> <span class="c1"># max lenght our sequences will be (e.g. how many words from a tweet our model see)</span>

<span class="n">text_vectorizer</span> <span class="o">=</span> <span class="n">TextVectorization</span><span class="p">(</span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">max_vocab_length</span><span class="p">,</span>
                                    <span class="n">output_mode</span> <span class="o">=</span><span class="s2">"int"</span><span class="p">,</span>
                                    <span class="n">output_sequence_length</span> <span class="o">=</span> <span class="n">max_length</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">text_vectorizer</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">sample_sentence</span> <span class="o">=</span> <span class="s2">"There's a flood in my street!"</span>
<span class="n">text_vectorizer</span><span class="p">([</span><span class="n">sample_sentence</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(1, 15), dtype=int64, numpy=
array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,
          0,   0]])&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Choose a random sentence from the training dataset and tokenize it</span>
<span class="n">random_sentence</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Original text: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">random_sentence</span><span class="si">}</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">        </span><span class="se">\n</span><span class="s2"> </span><span class="se">\n</span><span class="s2"> Vectorized version: "</span><span class="p">)</span>

<span class="n">text_vectorizer</span><span class="p">([</span><span class="n">random_sentence</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Original text: 
 @AlfaPedia It might have come out ONLY too burst as a Bomb making him suicide bomber         
 
 Vectorized version: 
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(1, 15), dtype=int64, numpy=
array([[   1,   15,  843,   24,  220,   36,  126,  150, 2174,   26,    3,
         108,  572,  158,   87]])&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">words_in_vocab</span> <span class="o">=</span> <span class="n">text_vectorizer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()</span> <span class="c1"># get all of the unique words in our training data</span>
<span class="n">top_5_words</span> <span class="o">=</span> <span class="n">words_in_vocab</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span> <span class="c1"># get the most common words</span>
<span class="n">bottom_5_words</span><span class="o">=</span> <span class="n">words_in_vocab</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span> <span class="c1"># get the least common words</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of words in vocab: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">words_in_vocab</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"5 most common words: </span><span class="si">{</span><span class="n">top_5_words</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"5 least common words: </span><span class="si">{</span><span class="n">bottom_5_words</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of words in vocab: 10000
5 most common words: ['', '[UNK]', 'the', 'a', 'in']
5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Creating-and-Embedding-using-an-Emedding-Layer">
<a class="anchor" href="#Creating-and-Embedding-using-an-Emedding-Layer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating and Embedding using an Emedding Layer<a class="anchor-link" href="#Creating-and-Embedding-using-an-Emedding-Layer"> </a>
</h4>
<p>To make our embedding we are going to use TensorFlow's Embedding layer.</p>
<p>The parameters we care most about for our embedding layer:</p>
<ul>
<li>
<code>input_dim</code> = the size of our vocabulary</li>
<li>
<code>output_dim</code> = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long </li>
<li>
<code>input_length</code> = length of sequences being passed to the embedding layer. </li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="n">embedding</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">max_vocab_length</span><span class="p">,</span> <span class="c1"># set input size</span>
                             <span class="n">output_dim</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
                             <span class="n">embeddings_initializer</span> <span class="o">=</span> <span class="s1">'uniform'</span><span class="p">,</span>
                             <span class="n">input_length</span> <span class="o">=</span> <span class="n">max_length</span> <span class="c1"># how long is each input</span>
                             <span class="p">)</span>

<span class="n">embedding</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.layers.embeddings.Embedding at 0x7f6a9734a110&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Get a random sentence from the training set</span>
<span class="n">random_sentence</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Original text:</span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">random_sentence</span><span class="si">}</span><span class="se">\</span>
<span class="s2">        </span><span class="se">\n</span><span class="s2"> </span><span class="se">\n</span><span class="s2">Embedded version: "</span><span class="p">)</span>

<span class="c1"># Embed the random sentence (turn it into dense vectors of fixed size)</span>
<span class="n">sample_embed</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">(</span><span class="n">text_vectorizer</span><span class="p">([</span><span class="n">random_sentence</span><span class="p">]))</span>
<span class="n">sample_embed</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Output" data-close="Show Output"></summary>
        <p>
</p>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Original text:
 Fall back this first break homebuyer miscalculation that could destruction thousands: MwjCdk        
 
Embedded version: 
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=
array([[[ 0.00859234, -0.02991412,  0.00175644, ...,  0.02193626,
          0.04184195, -0.02619057],
        [-0.00470889, -0.04967961, -0.01436696, ..., -0.00270484,
         -0.00828482,  0.01314512],
        [ 0.00405866,  0.02752711,  0.01645878, ..., -0.00964943,
          0.02267227,  0.00371256],
        ...,
        [ 0.00350211, -0.04788604,  0.00196681, ...,  0.02803201,
          0.00803728,  0.02167306],
        [ 0.00350211, -0.04788604,  0.00196681, ...,  0.02803201,
          0.00803728,  0.02167306],
        [ 0.00350211, -0.04788604,  0.00196681, ...,  0.02803201,
          0.00803728,  0.02167306]]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Check out a single token's embedding</span>
<span class="n">sample_embed</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">sample_embed</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">random_sentence</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Output" data-close="Show Output"></summary>
        <p>
</p>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&lt;tf.Tensor: shape=(128,), dtype=float32, numpy=
 array([ 0.00859234, -0.02991412,  0.00175644, -0.03367729, -0.03769684,
        -0.0291563 , -0.02644087, -0.03562082,  0.04090923, -0.02225679,
        -0.01017957, -0.04141713, -0.01146468, -0.04587493,  0.02797664,
        -0.02889217,  0.03275966, -0.02597183,  0.03522148, -0.04480093,
         0.0389016 , -0.0169893 ,  0.0142766 , -0.03043303,  0.04030218,
        -0.04211314,  0.03645163,  0.02257297,  0.02544535, -0.00259332,
        -0.01840631, -0.02087172, -0.03521866, -0.01772154, -0.04674302,
        -0.00397594,  0.03044703, -0.00820515, -0.04558386, -0.02431409,
         0.041382  ,  0.02238775,  0.00051622, -0.01694447, -0.01824627,
         0.03566995, -0.04934913, -0.00467784,  0.02524788,  0.02154641,
        -0.0166956 , -0.00147361,  0.02120248,  0.0378341 ,  0.00150269,
        -0.02470231, -0.04485737, -0.03325255, -0.0435687 , -0.02844893,
         0.04605688, -0.04954116,  0.01102605, -0.03360488, -0.00772928,
         0.00679797,  0.03716531, -0.04825834,  0.03694325, -0.04381819,
        -0.01490177,  0.01195564,  0.04442109,  0.02496224,  0.00903082,
        -0.00705872, -0.00284895, -0.0252423 ,  0.01289615,  0.00021081,
         0.01263725,  0.00752894, -0.02753489,  0.03229766, -0.02484094,
        -0.00039848, -0.02652047, -0.03955548, -0.04918641, -0.02551678,
         0.02933357,  0.03285935,  0.03242579, -0.01814985,  0.04405214,
        -0.03942751,  0.04565073,  0.02142942,  0.04559227,  0.02825892,
        -0.04690794,  0.04336696, -0.04502993,  0.03199968, -0.01844629,
        -0.01408292,  0.0381173 ,  0.02374512, -0.04499742,  0.00774354,
         0.03652367, -0.03725274, -0.0037598 , -0.03174049, -0.00407821,
         0.04460347,  0.00373029,  0.01934692,  0.04332647,  0.03005439,
        -0.00177516,  0.02241433, -0.01339862, -0.00733767,  0.03994515,
         0.02193626,  0.04184195, -0.02619057], dtype=float32)&gt;,
 TensorShape([128]),
 'F')</pre>
</div>

</div>

</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Modelling-a-text-dataset">
<a class="anchor" href="#Modelling-a-text-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modelling a text dataset<a class="anchor-link" href="#Modelling-a-text-dataset"> </a>
</h3>
<table>
<thead>
<tr>
<th>Experiment Number</th>
<th>Model</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Naive Bayes with TF-IDF encoder(baseline)</td>
</tr>
<tr>
<td>1</td>
<td>Feed-forward neural network(dense model)</td>
</tr>
<tr>
<td>2</td>
<td>LSTM(RNN)</td>
</tr>
<tr>
<td>3</td>
<td>GRU(RNN)</td>
</tr>
<tr>
<td>4</td>
<td>Bidirectional-LSTM(RNN)</td>
</tr>
<tr>
<td>5</td>
<td>1D Convolutional Neural Network</td>
</tr>
<tr>
<td>6</td>
<td>TensorFlow Hub Pretrained Feature Extractor</td>
</tr>
<tr>
<td>7</td>
<td>TensorFlow Hub Pretrained Feature Extractor (10% of data)</td>
</tr>
</tbody>
</table>
<p>Standards steps involved in running Modelling Experiments:</p>
<ul>
<li>Create a model</li>
<li>Build a model</li>
<li>Fit a model</li>
<li>Evaluate our model</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Model-0:-Naive-Bayes-with-TF-IDF-encoder">
<a class="anchor" href="#Model-0:-Naive-Bayes-with-TF-IDF-encoder" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model 0: Naive Bayes with TF-IDF encoder<a class="anchor-link" href="#Model-0:-Naive-Bayes-with-TF-IDF-encoder"> </a>
</h4>
<p>To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using the TF-IDF  formula to convert our words to numbers.</p>
<blockquote>
<p><strong>Note:</strong> It's common practice to use non-DL algorithms as a baseline because of their speed and later we can use DL algorithms to see if we can improve upon them.</p>
</blockquote>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># Create tokenization and modelling pipeline</span>
<span class="n">model_0</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
                    <span class="p">(</span><span class="s2">"tfidf"</span><span class="p">,</span> <span class="n">TfidfVectorizer</span><span class="p">()),</span> <span class="c1"># convert words to numbers using tfidf</span>
                    <span class="p">(</span><span class="s2">"clf"</span><span class="p">,</span> <span class="n">MultinomialNB</span><span class="p">())</span> <span class="c1"># Model the text</span>
                    
<span class="p">])</span>

<span class="c1"># Fit the pipeline to the training dat</span>
<span class="n">model_0</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">baseline_score</span> <span class="o">=</span> <span class="n">model_0</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">val_sentences</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Our baseline model achieves an accuracy of : </span><span class="si">{</span><span class="n">baseline_score</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Our baseline model achieves an accuracy of : 79.27%
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0    4342
1    3271
Name: target, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So, our model is doing better than guessing, since there are almost 50% of example of both label types in the dataset.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">baseline_preds</span> <span class="o">=</span> <span class="n">model_0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_sentences</span><span class="p">)</span>
<span class="n">baseline_preds</span><span class="p">[:</span><span class="mi">20</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Creating-an-evaluation-function-for-our-model-experiments">
<a class="anchor" href="#Creating-an-evaluation-function-for-our-model-experiments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating an evaluation function for our model experiments<a class="anchor-link" href="#Creating-an-evaluation-function-for-our-model-experiments"> </a>
</h4>
<p>We can evaluate all of our model's predictions with different metrics every time, instead of repeating the code, we can create a function so that we can reuse it later for all the model experiments.</p>
<p>The functions should output the following evaluation metrics:</p>
<ul>
<li>Accuracy</li>
<li>Precision</li>
<li>Recall</li>
<li>F1-Score</li>
</ul>
<p><strong>Resource:</strong> <a href="https://scikit-learn.org/stable/modules/model_evaluation.html">Metrics and scoring: quantifying the quality of predictions</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_recall_fscore_support</span>

<span class="k">def</span> <span class="nf">calculate_results</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
  <span class="sd">"""</span>

<span class="sd">  Calculates model accuracy, precision, recall and f1 score of a binary classification model</span>
<span class="sd">  """</span>
  <span class="c1"># Calculate the model accuracy</span>
  <span class="n">model_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
  <span class="c1"># Calculate model precision, recall and f1-score using "weighted" average</span>
  <span class="n">model_precision</span><span class="p">,</span> <span class="n">model_recall</span><span class="p">,</span> <span class="n">model_f1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span> <span class="o">=</span> <span class="s2">"weighted"</span><span class="p">)</span>
  <span class="n">model_results</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="n">model_accuracy</span><span class="p">,</span>
                   <span class="s2">"precision"</span><span class="p">:</span> <span class="n">model_precision</span><span class="p">,</span>
                   <span class="s2">"recall"</span><span class="p">:</span> <span class="n">model_recall</span><span class="p">,</span>
                   <span class="s2">"f1"</span><span class="p">:</span> <span class="n">model_f1</span><span class="p">}</span>

  <span class="k">return</span> <span class="n">model_results</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">baseline_results</span> <span class="o">=</span> <span class="n">calculate_results</span><span class="p">(</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">val_labels</span><span class="p">,</span>
                                     <span class="n">y_pred</span> <span class="o">=</span> <span class="n">baseline_preds</span><span class="p">)</span>

<span class="n">baseline_results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'accuracy': 79.26509186351706,
 'f1': 0.7862189758049549,
 'precision': 0.8111390004213173,
 'recall': 0.7926509186351706}</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-1:-A-Simple-Dense-Model">
<a class="anchor" href="#Model-1:-A-Simple-Dense-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model 1: A Simple Dense Model<a class="anchor-link" href="#Model-1:-A-Simple-Dense-Model"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">create_tensorboard_callback</span>

<span class="c1"># Create a directory to save TensorBoard logs</span>
<span class="n">SAVE_DIR</span> <span class="o">=</span> <span class="s2">"model_logs"</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">"string"</span><span class="p">)</span> <span class="c1"># inputs are 1-dimensional strings</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">text_vectorizer</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="c1"># turn the input text into numbers</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># create an embedding of the numerized numbers</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># lower the dimensionality of the embedding </span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"sigmoid"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># create the output layer, want binary outputs so use sigmoid activation</span>
<span class="n">model_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"model_1_dense"</span><span class="p">)</span> <span class="c1"># construct the model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_1</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: "model_1_dense"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 1)]               0         
                                                                 
 text_vectorization_4 (TextV  (None, 15)               0         
 ectorization)                                                   
                                                                 
 embedding_1 (Embedding)     (None, 15, 128)           1280000   
                                                                 
 global_average_pooling1d (G  (None, 128)              0         
 lobalAveragePooling1D)                                          
                                                                 
 dense (Dense)               (None, 1)                 129       
                                                                 
=================================================================
Total params: 1,280,129
Trainable params: 1,280,129
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_1</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span> <span class="o">=</span> <span class="s2">"binary_crossentropy"</span><span class="p">,</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
                <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_1_history</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">,</span>
                              <span class="n">train_labels</span><span class="p">,</span>
                              <span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                              <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">val_sentences</span><span class="p">,</span><span class="n">val_labels</span><span class="p">),</span>
                              <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">create_tensorboard_callback</span><span class="p">(</span><span class="n">dir_name</span> <span class="o">=</span> <span class="n">SAVE_DIR</span><span class="p">,</span>
                                                                       <span class="n">experiment_name</span> <span class="o">=</span> <span class="s2">"model_1_dense"</span> <span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Saving TensorBoard log files to: model_logs/model_1_dense/20220311-074354
Epoch 1/5
215/215 [==============================] - 5s 7ms/step - loss: 0.6103 - accuracy: 0.6875 - val_loss: 0.5359 - val_accuracy: 0.7598
Epoch 2/5
215/215 [==============================] - 1s 7ms/step - loss: 0.4411 - accuracy: 0.8156 - val_loss: 0.4690 - val_accuracy: 0.7848
Epoch 3/5
215/215 [==============================] - 1s 6ms/step - loss: 0.3472 - accuracy: 0.8600 - val_loss: 0.4571 - val_accuracy: 0.7953
Epoch 4/5
215/215 [==============================] - 1s 7ms/step - loss: 0.2837 - accuracy: 0.8924 - val_loss: 0.4681 - val_accuracy: 0.7927
Epoch 5/5
215/215 [==============================] - 1s 6ms/step - loss: 0.2371 - accuracy: 0.9126 - val_loss: 0.4866 - val_accuracy: 0.7887
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_1</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">val_sentences</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>24/24 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7887
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.4866005778312683, 0.7887139320373535]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_1_pred_probs</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_sentences</span><span class="p">)</span>
<span class="n">model_1_pred_probs</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(762, 1)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_1_pred_probs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([0.8119219], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These are prediction probabilites that came out of the output layer.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_1_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">model_1_pred_probs</span><span class="p">))</span>
<span class="n">model_1_preds</span><span class="p">[:</span><span class="mi">20</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(20,), dtype=float32, numpy=
array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
       0., 0., 0.], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_1_results</span> <span class="o">=</span> <span class="n">calculate_results</span><span class="p">(</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">val_labels</span><span class="p">,</span>
                                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_1_preds</span><span class="p">)</span>
<span class="n">model_1_results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'accuracy': 78.87139107611549,
 'f1': 0.7848945056280915,
 'precision': 0.7964015586347394,
 'recall': 0.7887139107611548}</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model_1_results</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">baseline_results</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([False, False, False, False])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Visualizing-learned-Embeddings:">
<a class="anchor" href="#Visualizing-learned-Embeddings:" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visualizing learned Embeddings:<a class="anchor-link" href="#Visualizing-learned-Embeddings:"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">words_in_vocab</span> <span class="o">=</span> <span class="n">text_vectorizer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">words_in_vocab</span><span class="p">),</span> <span class="n">words_in_vocab</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_1</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: "model_1_dense"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 1)]               0         
                                                                 
 text_vectorization_4 (TextV  (None, 15)               0         
 ectorization)                                                   
                                                                 
 embedding_1 (Embedding)     (None, 15, 128)           1280000   
                                                                 
 global_average_pooling1d (G  (None, 128)              0         
 lobalAveragePooling1D)                                          
                                                                 
 dense (Dense)               (None, 1)                 129       
                                                                 
=================================================================
Total params: 1,280,129
Trainable params: 1,280,129
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># (these numerical representations of each token in our training data, which has been learned for 5 epochs)</span>
<span class="n">embed_weights</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s2">"embedding_1"</span><span class="p">)</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">embed_weights</span> <span class="c1"># Same size as vocab size and embedding_dim</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[ 0.02186958, -0.06763938,  0.02146152, ...,  0.01258572,
         0.02883859,  0.00023849],
       [-0.02620384, -0.02298776, -0.02039188, ...,  0.00896182,
         0.03781693, -0.03427465],
       [ 0.0165944 ,  0.01236528,  0.03275075, ...,  0.03906085,
         0.05525858, -0.03807979],
       ...,
       [-0.0099979 ,  0.04100901, -0.04915455, ...,  0.03296768,
         0.03509828,  0.02508564],
       [ 0.01705603, -0.04142731, -0.00240709, ..., -0.05540716,
         0.0721622 , -0.03262765],
       [ 0.06986112, -0.09984355,  0.02866708, ..., -0.02748252,
         0.08362035, -0.03691495]], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">embed_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># same size as vocab size and embedding_dim</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(10000, 128)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we have got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it. To do so, Tensorflow has a tool called projector: <a href="https://projector.tensorflow.org/">https://projector.tensorflow.org/</a></p>
<p>And TensorFlow also has an incredible guide on word embeddings: <a href="https://www.tensorflow.org/text/guide/word_embeddings">https://www.tensorflow.org/text/guide/word_embeddings</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">io</span>
<span class="n">out_v</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">'vectors.tsv'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>
<span class="n">out_m</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">'metadata.tsv'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words_in_vocab</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">continue</span>  <span class="c1"># skip 0, it's padding.</span>
  <span class="n">vec</span> <span class="o">=</span> <span class="n">embed_weights</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
  <span class="n">out_v</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">])</span> <span class="o">+</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
  <span class="n">out_m</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">word</span> <span class="o">+</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="n">out_v</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">out_m</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">try</span><span class="p">:</span>
  <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
  <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'vectors.tsv'</span><span class="p">)</span>
  <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'metadata.tsv'</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
  <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="d7aaa473-a857-4b62-a4c8-da03bd1d9b39"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#d7aaa473-a857-4b62-a4c8-da03bd1d9b39');

    async function download(id, filename, size) {
      if (!google.colab.kernel.accessAllowed) {
        return;
      }
      const div = document.createElement('div');
      const label = document.createElement('label');
      label.textContent = `Downloading "${filename}": `;
      div.appendChild(label);
      const progress = document.createElement('progress');
      progress.max = size;
      div.appendChild(progress);
      document.body.appendChild(div);

      const buffers = [];
      let downloaded = 0;

      const channel = await google.colab.kernel.comms.open(id);
      // Send a message to notify the kernel that we're ready.
      channel.send({})

      for await (const message of channel.messages) {
        // Send a message to notify the kernel that we're ready.
        channel.send({})
        if (message.buffers) {
          for (const buffer of message.buffers) {
            buffers.push(buffer);
            downloaded += buffer.byteLength;
            progress.value = downloaded;
          }
        }
      }
      const blob = new Blob(buffers, {type: 'application/binary'});
      const a = document.createElement('a');
      a.href = window.URL.createObjectURL(blob);
      a.download = filename;
      div.appendChild(a);
      a.click();
      div.remove();
    }
  
</script>
</div>

</div>

<div class="output_area">




<div id="6433d124-1241-431f-9432-00e12d1641fe"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#6433d124-1241-431f-9432-00e12d1641fe');
download("download_57b50ad8-2926-41b1-871d-0cca87b2a9dd", "vectors.tsv", 15361836)
</script>
</div>

</div>

<div class="output_area">




<div id="b3dd809a-89e7-4be3-b8f3-0adc1c19d086"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#b3dd809a-89e7-4be3-b8f3-0adc1c19d086');

    async function download(id, filename, size) {
      if (!google.colab.kernel.accessAllowed) {
        return;
      }
      const div = document.createElement('div');
      const label = document.createElement('label');
      label.textContent = `Downloading "${filename}": `;
      div.appendChild(label);
      const progress = document.createElement('progress');
      progress.max = size;
      div.appendChild(progress);
      document.body.appendChild(div);

      const buffers = [];
      let downloaded = 0;

      const channel = await google.colab.kernel.comms.open(id);
      // Send a message to notify the kernel that we're ready.
      channel.send({})

      for await (const message of channel.messages) {
        // Send a message to notify the kernel that we're ready.
        channel.send({})
        if (message.buffers) {
          for (const buffer of message.buffers) {
            buffers.push(buffer);
            downloaded += buffer.byteLength;
            progress.value = downloaded;
          }
        }
      }
      const blob = new Blob(buffers, {type: 'application/binary'});
      const a = document.createElement('a');
      a.href = window.URL.createObjectURL(blob);
      a.download = filename;
      div.appendChild(a);
      a.click();
      div.remove();
    }
  
</script>
</div>

</div>

<div class="output_area">




<div id="4dd6e83d-6b40-4cc6-9c6f-7fa120893f2c"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#4dd6e83d-6b40-4cc6-9c6f-7fa120893f2c');
download("download_beb07ff0-3959-47e9-9a62-be18a6de7ceb", "metadata.tsv", 80388)
</script>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">plot_functions</span><span class="p">(</span><span class="n">k_values</span><span class="p">,</span> <span class="n">m_values</span><span class="p">,</span> <span class="n">n_values</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">create_tensorboard_callback</span><span class="p">(</span><span class="n">dirname</span><span class="p">,</span> <span class="n">dirpath</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">text_dataset_from_directory</span><span class="p">(</span>
    <span class="n">directory</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="s1">'inferred'</span><span class="p">,</span> <span class="n">label_mode</span><span class="o">=</span><span class="s1">'int'</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">follow_links</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>




<a href="#top">Back to top of page</a>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="sandeshkatakam/My-Machine_learning-Blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/My-Machine_learning-Blog/deep%20learning/neuralnetworks/tensorflow/natural-language-processing(nlp)/2022/05/11/Natural-Language-Processing-with-TensorFlow.html" hidden></a>
  <!-- <button id="back-to-top-btn"><i class="fas fa-angle-double-up"></i></button> -->
  <a href="#" class="scrollup">Scroll</a> 
</article>



      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/My-Machine_learning-Blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/My-Machine_learning-Blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/My-Machine_learning-Blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Blog related to Machine learning and Deep learning.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/sandeshkatakam" target="_blank" title="sandeshkatakam"><svg class="svg-icon grey"><use xlink:href="/My-Machine_learning-Blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/sandeshkatakam" target="_blank" title="sandeshkatakam"><svg class="svg-icon grey"><use xlink:href="/My-Machine_learning-Blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
